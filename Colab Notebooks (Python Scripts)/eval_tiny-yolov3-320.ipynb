{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"eval_tiny-yolov3-320.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1dF19UE-9XeUlYXuzuaW0PEbG87vt9oG0","authorship_tag":"ABX9TyMCdnUMU4ikVKBovrx8KsOo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3Gufa1yf8RI","executionInfo":{"status":"ok","timestamp":1613775251242,"user_tz":300,"elapsed":4589,"user":{"displayName":"Sagar Doshi","photoUrl":"https://lh4.googleusercontent.com/-Vn-rqxkimuQ/AAAAAAAAAAI/AAAAAAAAAoE/AV9jCTwK3TU/s64/photo.jpg","userId":"01260134573907799840"}},"outputId":"0b645f06-e076-4e02-977d-2a1ed0f0cc5e"},"source":["!pip install natsort"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: natsort in /usr/local/lib/python3.6/dist-packages (5.5.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WayxCi9qTQ7-","executionInfo":{"status":"ok","timestamp":1614210696361,"user_tz":300,"elapsed":282,"user":{"displayName":"Sagar Doshi","photoUrl":"https://lh4.googleusercontent.com/-Vn-rqxkimuQ/AAAAAAAAAAI/AAAAAAAAAoE/AV9jCTwK3TU/s64/photo.jpg","userId":"01260134573907799840"}}},"source":["import json\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import os\r\n","\r\n","from matplotlib.patches import Rectangle\r\n","from natsort import natsorted\r\n","from tqdm import tqdm\r\n","\r\n","%matplotlib inline\r\n","\r\n","import tensorflow as tf\r\n","from tensorflow.keras.preprocessing.image import *"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_jW57FeDa4R","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1614210697693,"user_tz":300,"elapsed":309,"user":{"displayName":"Sagar Doshi","photoUrl":"https://lh4.googleusercontent.com/-Vn-rqxkimuQ/AAAAAAAAAAI/AAAAAAAAAoE/AV9jCTwK3TU/s64/photo.jpg","userId":"01260134573907799840"}},"outputId":"feaccbf7-3cd4-4323-86d1-0e51c240d876"},"source":["os.chdir('/content/drive/MyDrive/EE113DB')\r\n","print(os.getcwd())\r\n","\r\n","dataDir = 'custom_datasets320'\r\n","dataType = 'val2017'\r\n","\r\n","img_filenames = natsorted(os.listdir(os.path.join(dataDir, 'images', dataType)))\r\n","img_ids = [os.path.splitext(f)[0] for f in img_filenames] # get rid of '.jpg' extension\r\n","\r\n","with open(os.path.join(dataDir, 'annotations', '{}bboxes.json'.format(dataType) ), 'r') as json_file:\r\n","  img_bboxes_dict = json.load(json_file)\r\n","  json_file.close()\r\n","\r\n","'''\r\n","Custom JSON hierarchy:\r\n","img_id\r\n","    cat\r\n","        bbox1\r\n","        bbox2\r\n","        bbox3\r\n","        ...\r\n","    cat \r\n","        bbox1\r\n","        bbox2\r\n","        bbox3\r\n","        ...\r\n","'''"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/EE113DB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nCustom JSON hierarchy:\\nimg_id\\n    cat\\n        bbox1\\n        bbox2\\n        bbox3\\n        ...\\n    cat \\n        bbox1\\n        bbox2\\n        bbox3\\n        ...\\n'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Nge18CPPlJHT","executionInfo":{"status":"ok","timestamp":1614210699167,"user_tz":300,"elapsed":808,"user":{"displayName":"Sagar Doshi","photoUrl":"https://lh4.googleusercontent.com/-Vn-rqxkimuQ/AAAAAAAAAAI/AAAAAAAAAoE/AV9jCTwK3TU/s64/photo.jpg","userId":"01260134573907799840"}}},"source":["# based on https://github.com/experiencor/keras-yolo3\r\n","import numpy as np\r\n","from numpy import expand_dims\r\n","from keras.models import load_model\r\n","from keras.preprocessing.image import load_img\r\n","from keras.preprocessing.image import img_to_array\r\n","from matplotlib import pyplot\r\n","from matplotlib.patches import Rectangle\r\n"," \r\n","class BoundBox:\r\n","\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\r\n","\t\tself.xmin = xmin\r\n","\t\tself.ymin = ymin\r\n","\t\tself.xmax = xmax\r\n","\t\tself.ymax = ymax\r\n","\t\tself.objness = objness\r\n","\t\tself.classes = classes\r\n","\t\tself.label = -1\r\n","\t\tself.score = -1\r\n"," \r\n","\tdef get_label(self):\r\n","\t\tif self.label == -1:\r\n","\t\t\tself.label = np.argmax(self.classes)\r\n"," \r\n","\t\treturn self.label\r\n"," \r\n","\tdef get_score(self):\r\n","\t\tif self.score == -1:\r\n","\t\t\tself.score = self.classes[self.get_label()]\r\n"," \r\n","\t\treturn self.score\r\n"," \r\n","def _sigmoid(x):\r\n","\treturn 1. / (1. + np.exp(-x))\r\n"," \r\n","def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\r\n","  grid_h, grid_w = netout.shape[:2]\r\n","  nb_box = 3\r\n","  netout = netout.reshape((grid_h, grid_w, nb_box, -1)) # Converts to \r\n","  nb_class = netout.shape[-1] - 5\r\n","  boxes = []\r\n","  netout[..., :2]  = _sigmoid(netout[..., :2])\r\n","  netout[..., 4:]  = _sigmoid(netout[..., 4:])\r\n","  netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\r\n","  netout[..., 5:] *= netout[..., 5:] > obj_thresh\r\n","\r\n","  for i in range(grid_h*grid_w):\r\n","    row = i / grid_w\r\n","    col = i % grid_w\r\n","    for b in range(nb_box):\r\n","      # 4th element is objectness score\r\n","      objectness = netout[int(row)][int(col)][b][4]\r\n","      if(objectness.all() <= obj_thresh): continue\r\n","      # first 4 elements are x, y, w, and h\r\n","      x, y, w, h = netout[int(row)][int(col)][b][:4]\r\n","      x = (col + x) / grid_w # center position, unit: image width\r\n","      y = (row + y) / grid_h # center position, unit: image height\r\n","      w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\r\n","      h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\r\n","      # last elements are class probabilities\r\n","      classes = netout[int(row)][col][b][5:]\r\n","      box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\r\n","      boxes.append(box)\r\n","  return boxes\r\n"," \r\n","def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\r\n","\tnew_w, new_h = net_w, net_h\r\n","\tfor i in range(len(boxes)):\r\n","\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\r\n","\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\r\n","\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\r\n","\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\r\n","\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\r\n","\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\r\n"," \r\n","def _interval_overlap(interval_a, interval_b):\r\n","\tx1, x2 = interval_a\r\n","\tx3, x4 = interval_b\r\n","\tif x3 < x1:\r\n","\t\tif x4 < x1:\r\n","\t\t\treturn 0\r\n","\t\telse:\r\n","\t\t\treturn min(x2,x4) - x1\r\n","\telse:\r\n","\t\tif x2 < x3:\r\n","\t\t\t return 0\r\n","\t\telse:\r\n","\t\t\treturn min(x2,x4) - x3\r\n"," \r\n","def bbox_iou(box1, box2):\r\n","\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\r\n","\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\r\n","\tintersect = intersect_w * intersect_h\r\n","\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\r\n","\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\r\n","\tunion = w1*h1 + w2*h2 - intersect\r\n","\treturn float(intersect) / union\r\n"," \r\n","def do_nms(boxes, nms_thresh):\r\n","\tif len(boxes) > 0:\r\n","\t\tnb_class = len(boxes[0].classes)\r\n","\telse:\r\n","\t\treturn\r\n","\tfor c in range(nb_class):\r\n","\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\r\n","\t\tfor i in range(len(sorted_indices)):\r\n","\t\t\tindex_i = sorted_indices[i]\r\n","\t\t\tif boxes[index_i].classes[c] == 0: continue\r\n","\t\t\tfor j in range(i+1, len(sorted_indices)):\r\n","\t\t\t\tindex_j = sorted_indices[j]\r\n","\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\r\n","\t\t\t\t\tboxes[index_j].classes[c] = 0\r\n","\r\n","# get all of the results above a threshold\r\n","def get_boxes(boxes, labels, thresh):\r\n","\tv_boxes, v_labels, v_scores = list(), list(), list()\r\n","\t# enumerate all boxes\r\n","\tfor box in boxes:\r\n","\t\t# enumerate all possible labels\r\n","\t\tfor i in range(len(labels)):\r\n","\t\t\t# check if the threshold for this label is high enough\r\n","\t\t\tif box.classes[i] > thresh:\r\n","\t\t\t\tv_boxes.append(box)\r\n","\t\t\t\tv_labels.append(labels[i])\r\n","\t\t\t\tv_scores.append(box.classes[i]*100)\r\n","\t\t\t\t# don't break, many labels may trigger for one box\r\n","\treturn v_boxes, v_labels, v_scores\r\n"," \r\n","# draw all results\r\n","def draw_boxes(filename, v_boxes, v_labels, v_scores):\r\n","\t# load the image\r\n","\tdata = pyplot.imread(filename)\r\n","\t# plot the image\r\n","\tpyplot.imshow(data)\r\n","\t# get the context for drawing boxes\r\n","\tax = pyplot.gca()\r\n","\t# plot each box\r\n","\tfor i in range(len(v_boxes)):\r\n","\t\tbox = v_boxes[i]\r\n","\t\t# get coordinates\r\n","\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\r\n","\t\t# calculate width and height of the box\r\n","\t\twidth, height = x2 - x1, y2 - y1\r\n","\t\t# create the shape\r\n","\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\r\n","\t\t# draw the box\r\n","\t\tax.add_patch(rect)\r\n","\t\t# draw text and score in top left corner\r\n","\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\r\n","\t\tpyplot.text(x1, y1, label, color='white')\r\n","\t# show the plot\r\n","\tpyplot.show()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmOO_9Wp4TSQ","executionInfo":{"status":"ok","timestamp":1614210700914,"user_tz":300,"elapsed":282,"user":{"displayName":"Sagar Doshi","photoUrl":"https://lh4.googleusercontent.com/-Vn-rqxkimuQ/AAAAAAAAAAI/AAAAAAAAAoE/AV9jCTwK3TU/s64/photo.jpg","userId":"01260134573907799840"}}},"source":["def load_img_array(image_path, target_size=(320,320)):\r\n","  image = load_img(image_path, target_size=target_size)\r\n","  image = img_to_array(image)\r\n","  \r\n","  # scale pixel values to [0, 1]\r\n","  image = image.astype('float32')\r\n","  image /= 255.0\r\n","\r\n","  return image\r\n","\r\n","def compute_iou_xywh(box1, box2):\r\n","  x1, y1, w1, h1 = box1\r\n","  x2, y2, w2, h2 = box2\r\n","\r\n","  bbox1 = BoundBox(x1, y1, x1+w1, y1+h1)\r\n","  bbox2 = BoundBox(x2, y2, x2+w2, y2+h2)\r\n","\r\n","  return bbox_iou(bbox1, bbox2)\r\n","\r\n","def get_max_iou(box, box_list):\r\n","  if box_list == []:\r\n","    return 0.0,[]\r\n","  iou_arr = []\r\n","  for p_box in box_list:\r\n","    iou_arr.append(compute_iou_xywh(box, p_box))\r\n","  iou_arr = np.asarray(iou_arr)\r\n","  idx_max = np.argmax(iou_arr)\r\n","\r\n","  return iou_arr[idx_max], box_list[idx_max]\r\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLgKgIbgQyy_"},"source":["# Run inference on dataset -> create results JSON file (if you want to use the COCO evaluation API)\r\n","# Alternatively -> create custom evaluation code to focus only on the relevant classes\r\n","\r\n","model = tf.keras.models.load_model('set_yolov3-tiny.h5')\r\n","anchors = [[115, 73, 119,199, 242,238], [12, 18,  37, 49,  52,132]]\r\n","class_threshold = 0.4 # may want to lower to 0.1\r\n","input_h, input_w = 320, 320\r\n","nms_thresh = 0.25\r\n","\r\n","# TODO - rerun but with 'motorcycle' instead of 'motorbike' - TYPO in experiencor REPO\r\n","labels = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"aeroplane\", \"bus\", \"train\", \"truck\",\r\n","\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\r\n","\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\r\n","\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\r\n","\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\r\n","\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\r\n","\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\r\n","\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\r\n","\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\r\n","\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\r\n","\r\n","\r\n","relevant_cats = ['car', 'bicycle', 'motorcycle', 'bus', 'truck', \r\n","                 'traffic light', 'stop sign', 'parking meter', 'fire hydrant']\r\n","\r\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDTlRA4ZRuTf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614212776730,"user_tz":300,"elapsed":415219,"user":{"displayName":"Sagar Doshi","photoUrl":"https://lh4.googleusercontent.com/-Vn-rqxkimuQ/AAAAAAAAAAI/AAAAAAAAAoE/AV9jCTwK3TU/s64/photo.jpg","userId":"01260134573907799840"}},"outputId":"6720ce9a-2155-40a1-fb57-2d6e0a5d2e24"},"source":["# https://pro.arcgis.com/en/pro-app/latest/tool-reference/image-analyst/how-compute-accuracy-for-object-detection-works.htm#:~:text=Precision%E2%80%94%20Precision%20is%20the%20ratio,the%20precision%20is%2090%20percent.\r\n","\r\n","# For debug, just do 2-10 images\r\n","# img_filenames = img_filenames[0:2]\r\n","# img_ids = img_ids[0:2]\r\n","\r\n","# TODO - for now just computing precision/recall in a multi-class T/F sense\r\n","# Should we be evaluating the scores of the model?\r\n","\r\n","# TODO - how we compute network performance MUST be mentioned in the final report\r\n","\r\n","tp_dict = {cat:0 for cat in relevant_cats}\r\n","fp_dict = {cat:0 for cat in relevant_cats}\r\n","fn_dict = {cat:0 for cat in relevant_cats}\r\n","IOU_THRESH = 0.75 # Typical value used, try 0.25 (better) and 0.75 (worse)\r\n","# is meant to reward networks with better localization\r\n","\r\n","for i in tqdm(range(len(img_filenames))):\r\n","  img_path = os.path.join(dataDir, 'images', dataType,  img_filenames[i])\r\n","  img = np.expand_dims(load_img_array(img_path), axis=0)\r\n","  img_id = img_ids[i]\r\n","  \r\n","  yhat = model.predict(img)\r\n","  boxes = []\r\n","  for i in range(len(yhat)):\r\n","    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\r\n","\r\n","  # correct the sizes of the bounding boxes for the shape of the image\r\n","  correct_yolo_boxes(boxes, 320, 320, 320, 320)\r\n","\r\n","  # Suppress non-maximal (confidences) boxes with high overlap (IoU)\r\n","  do_nms(boxes, nms_thresh)\r\n","\r\n","  # Get bounding boxes above score theshold\r\n","  v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\r\n","  \r\n","  # TODO - only for demo & debug purposes\r\n","  # draw_boxes(img_path, v_boxes, v_labels, v_scores) \r\n","\r\n","  # Populate gt_dict and pred_dict \r\n","  gt_dict = img_bboxes_dict[img_id]\r\n","  pred_dict = {cat:[] for cat in gt_dict.keys()}\r\n","\r\n","  for i, v_box in enumerate(v_boxes):\r\n","    x = v_box.xmin\r\n","    y = v_box.ymin\r\n","    w = v_box.xmax - v_box.xmin\r\n","    h = v_box.ymax - v_box.ymin\r\n","\r\n","    cat = v_labels[i]\r\n","    score = v_scores[i]\r\n","    if cat in relevant_cats:\r\n","      pred_dict[cat].append([x,y,w,h]) # .append(([x,y,w,h], score))\r\n","\r\n","  # Compute tp and fn\r\n","  for cat in gt_dict.keys():\r\n","    for bbox in gt_dict[cat]:\r\n","      max_iou, p_box = get_max_iou(bbox, pred_dict[cat])\r\n","      if max_iou >= IOU_THRESH:\r\n","        tp_dict[cat] += 1\r\n","      else:\r\n","        fn_dict[cat] += 1\r\n","\r\n","  # Compute fp\r\n","  for cat in relevant_cats:\r\n","    if pred_dict[cat] == []:\r\n","      continue\r\n","    for bbox in pred_dict[cat]:\r\n","      max_iou, g_box = get_max_iou(bbox, gt_dict[cat])\r\n","      if max_iou <= IOU_THRESH:\r\n","        fp_dict[cat] += 1\r\n","\r\n","print(\"\\n\")\r\n","print(tp_dict)\r\n","print(fp_dict)\r\n","print(fn_dict)\r\n","\r\n","# '''\r\n","# gt_dict:\r\n","# cat\r\n","#   bbox1\r\n","#   bbox2\r\n","#   bbox3\r\n","#   ...\r\n","# cat \r\n","#   bbox1\r\n","#   bbox2\r\n","#   bbox3\r\n","#   ...\r\n","\r\n","\r\n","# pred_dict: for now, not including scores\r\n","# cat\r\n","#   bbox1, score1\r\n","#   bbox2, score2\r\n","#   bbox3, score3\r\n","#   ...\r\n","# cat \r\n","#   bbox1, score1\r\n","#   bbox2, score2\r\n","#   bbox3, score3\r\n","#   ...\r\n","# '''\r\n","\r\n","# precision = tp/(tp + fp)\r\n","# recall = tp/(tp + fn)\r\n","# f1 = (Precision × Recall)/[(Precision + Recall)/2]\r\n","\r\n","eps = 1e-6 # avoid div by zero errors -> motorbike name mismatch\r\n","\r\n","precision_dict = {cat: tp_dict[cat]/(eps + tp_dict[cat] + fp_dict[cat]) for cat in relevant_cats}\r\n","recall_dict = {cat: tp_dict[cat]/(eps + tp_dict[cat] + fn_dict[cat]) for cat in relevant_cats}\r\n","f1_dict = {cat: 2*precision_dict[cat]*recall_dict[cat]/(eps + precision_dict[cat] + recall_dict[cat]) for cat in relevant_cats}\r\n","\r\n","json_filenames_to_save = ['precision.json', 'recall.json', 'f1.json', 'tp.json', 'fp.json', 'fn.json']\r\n","dicts = [precision_dict, recall_dict, f1_dict, tp_dict, fp_dict, fn_dict]\r\n","\r\n","for i, filename in enumerate(json_filenames_to_save):\r\n","  with open(os.path.join('evaluation_results','IOU75', filename), 'w') as fp:\r\n","    json.dump(dicts[i], fp, sort_keys=True, indent=4)\r\n","    fp.close()\r\n","\r\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["100%|██████████| 769/769 [06:54<00:00,  1.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","{'car': 14, 'bicycle': 3, 'motorcycle': 9, 'bus': 14, 'truck': 4, 'traffic light': 2, 'stop sign': 10, 'parking meter': 3, 'fire hydrant': 6}\n","{'car': 362, 'bicycle': 39, 'motorcycle': 63, 'bus': 87, 'truck': 50, 'traffic light': 41, 'stop sign': 27, 'parking meter': 9, 'fire hydrant': 33}\n","{'car': 476, 'bicycle': 150, 'motorcycle': 254, 'bus': 197, 'truck': 234, 'traffic light': 56, 'stop sign': 30, 'parking meter': 35, 'fire hydrant': 61}\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wdQ5FpK9w28M"},"source":["# precision = tp/(tp + fp)\r\n","# recall = tp/(tp + fn)\r\n","# f1 = (Precision × Recall)/[(Precision + Recall)/2]\r\n","\r\n","eps = 1e-6 # avoid div by zero errors -> motorbike name mismatch\r\n","\r\n","precision_dict = {cat: tp_dict[cat]/(eps + tp_dict[cat] + fp_dict[cat]) for cat in relevant_cats}\r\n","recall_dict = {cat: tp_dict[cat]/(eps + tp_dict[cat] + fn_dict[cat]) for cat in relevant_cats}\r\n","f1_dict = {cat: 2*precision_dict[cat]*recall_dict[cat]/(eps + precision_dict[cat] + recall_dict[cat]) for cat in relevant_cats}\r\n","\r\n","json_filenames_to_save = ['precision.json', 'recall.json', 'f1.json', 'tp.json', 'fp.json', 'fn.json']\r\n","dicts = [precision_dict, recall_dict, f1_dict, tp_dict, fp_dict, fn_dict]\r\n","\r\n","for i, filename in enumerate(json_filenames_to_save):\r\n","  with open(os.path.join('evaluation_results','IOU75', filename), 'w') as fp:\r\n","    json.dump(dicts[i], fp, sort_keys=True, indent=4)\r\n","    fp.close()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBcP6ZA7EyY1"},"source":[""],"execution_count":null,"outputs":[]}]}